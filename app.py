'''import streamlit as st
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import re

# Load the model and tokenizer
output_dir = './saved_model_seven'
model = AutoModelForSequenceClassification.from_pretrained(output_dir)
tokenizer = AutoTokenizer.from_pretrained(output_dir)
model.eval()

# Preprocessing function
def preprocess(text):
    text = re.sub(r'[^\w\s]', '', text)  # Remove punctuation
    return text

# Prediction function
def predict(text, model, tokenizer):
    # Preprocess the text
    preprocessed_text = preprocess(text)

    # Tokenize the input
    inputs = tokenizer(preprocessed_text, return_tensors="pt", padding=True, truncation=True, max_length=128)

    # Get the model's predictions
    with torch.no_grad():  # Disable gradient calculation
        outputs = model(**inputs)

    # Get the predicted label (0 for human, 1 for AI)
    predicted_label = torch.argmax(outputs.logits, dim=1).item()

    # Map the predicted label to human-readable output
    label_map = {0: "Human-generated text", 1: "AI-generated text"}

    return label_map[predicted_label]

# Streamlit app layout
st.title("AI Text Detection")
st.write("Enter some text below and check whether it's AI-generated or Human-generated. Over 100 Words for better accuracy.")

# User input
user_input = st.text_area("Input Text")

if st.button("Predict"):
    if user_input.strip():
        prediction = predict(user_input, model, tokenizer)
        st.write(f"Prediction: {prediction}")
    else:
        st.warning("Please enter some text.")
'''

import streamlit as st
import requests
import os
from dotenv import load_dotenv
load_dotenv()

# Hugging Face API setup
API_URL = "https://api-inference.huggingface.co/models/AloysiusJoy/AIDetectApp"
headers = {
    "Authorization": f"Bearer {os.getenv('HF_API_TOKEN')}"
}

# Prediction function using Hugging Face Inference API
def query(payload):
    response = requests.post(API_URL, headers=headers, json=payload)
    try:
        return response.json()
    except Exception as e:
        return {"error": str(e)}

# --- Streamlit App Layout ---
st.set_page_config(page_title="AI Text Detector", layout="centered")

st.markdown("<h1 style='text-align: center;'>üß† AI Text Detection App</h1>", unsafe_allow_html=True)
st.markdown("<p style='text-align: center;'>Enter a paragraph and find out whether it was generated by AI or a human. For better accuracy, try using 100+ words.</p>", unsafe_allow_html=True)

# Input box
user_input = st.text_area("üìù Paste your text here", height=200)

# Layout for button
col1, col2, col3 = st.columns([2, 1, 1])
with col1:
    if st.button("üîç Predict"):
        if user_input.strip():
            output = query({"inputs": user_input})

            # Handle response
            if "error" in output:
                st.error(f"Error: {output['error']}")
            elif isinstance(output, list) and isinstance(output[0], list):
                label_map = {
                    "LABEL_0": "üßë‚Äçüíº Human-generated text",
                    "LABEL_1": "ü§ñ AI-generated text"
                }
                top_label = output[0][0]["label"]
                confidence = output[0][0]["score"]
                readable_label = label_map.get(top_label, top_label)

                st.success(f"**Prediction:** {readable_label}\n\n**Confidence:** {confidence:.2%}")
            else:
                st.write("Response:", output)
        else:
            st.warning("‚ö†Ô∏è Please enter some text.")


